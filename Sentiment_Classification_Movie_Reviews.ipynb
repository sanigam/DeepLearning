{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num reviews: 25000 Num Lables: 25000\n",
      "review: 24500 ONE OF THE BEST LOW BUDGET MOVIES FROM GERMANY  IS THIS IS THE DARK SIDE OF NEW AGE  IF YOU BELIEVE IN ESOTERIC  PLEASE DON  T WATCH THIS MOVIE  IT BLOWS ALL YOUR POSITIVE FANTASIES AWAY . THIS MOVIE SHOWS THAT BEYOND THE PEACEFUL FAADE OF SPIRITUAL SOUL SEARCHING LIES A WORLD OF EXTREME TRANSGRESSIONS AND TERROR . I HOPE THERE WILL BE A   MM COPY SOON  ANDREAS MARSCHALL  S FIRST FILM IS JUST THE BEGINNING OF A NEW AREA  MAKING MOVIES WITH A FEW EUROS  I  M WAITING FOR THE SECOND HIT    Lable: 24500 POSITIVE\n"
     ]
    }
   ],
   "source": [
    "## Added to read files##\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "g = open('reviews.txt','r') \n",
    "reviews = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()\n",
    "print ( \"Num reviews:\", len(reviews), \"Num Lables:\", len(labels))\n",
    "i=24500\n",
    "print ( \"review:\",i, reviews[i], \"Lable:\",i, labels[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: -Copy the SentimentNetwork class from Project 5 lesson\n",
    "#       -Modify it according to the above instructions \n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews, labels, min_count = 10,polarity_cutoff = 0.1, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels, polarity_cutoff, min_count)\n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels,polarity_cutoff, min_count):\n",
    "        # Project 6\n",
    "        positive_counts = Counter()\n",
    "        negative_counts = Counter()\n",
    "        total_counts = Counter()\n",
    "        \n",
    "        for i in range ( len(reviews)):\n",
    "            if (labels[i] == 'POSITIVE'):\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    positive_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "            else:\n",
    "                for word in reviews[i].lower().split(\" \"):\n",
    "                    negative_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "        pos_neg_ratios = Counter()\n",
    "        \n",
    "        for term, cnt in list (total_counts.most_common()):\n",
    "            if (cnt>50):\n",
    "                pos_neg_ratio = positive_counts[term]/float(negative_counts[term]+1)\n",
    "                pos_neg_ratios[term] = pos_neg_ratio\n",
    "        \n",
    "        for word, ratio in pos_neg_ratios.most_common():\n",
    "            if ( ratio > 1 ) :\n",
    "                pos_neg_ratios[word] = np.log(ratio)\n",
    "            else:\n",
    "                pos_neg_ratios[word] = -np.log( (1/(ratio+.01) ))\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        review_vocab = set()\n",
    "        # TODO: populate review_vocab with all of the words in the given reviews\n",
    "        #       Remember to split reviews into individual words \n",
    "        #       using \"split(' ')\" instead of \"split()\".\n",
    "        for review in reviews:\n",
    "            for word in review.lower().split(\" \"):\n",
    "                if (total_counts[word] > min_count):\n",
    "                    if (word in pos_neg_ratios.keys() ):\n",
    "                       # print (\"Word:\", word, pos_neg_ratios[word])\n",
    "                        if ( (pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                            review_vocab.add(word)\n",
    "                    else:\n",
    "                        review_vocab.add(word)\n",
    "                        \n",
    "            \n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        # TODO: populate label_vocab with all of the words in the given labels.\n",
    "        #       There is no need to split the labels because each one is a single word.\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        # TODO: populate self.word2index with indices for all the words in self.review_vocab\n",
    "        #       like you saw earlier in the notebook\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word]  = i\n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        # TODO: do the same thing you did for self.word2index and self.review_vocab, \n",
    "        #       but for self.label2index and self.label_vocab instead\n",
    "        for i, word in enumerate(self.label_vocab):\n",
    "            self.label2index[label]  = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Store the number of nodes in input, hidden, and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "        \n",
    "        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n",
    "        #       the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "        \n",
    "        # TODO: initialize self.weights_1_2 as a matrix of random values. \n",
    "        #       These are the weights between the hidden layer and the output layer.\n",
    "        \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # TODO: Create the input layer, a two-dimensional matrix with shape \n",
    "        #       1 x input_nodes, with all values initialized to zero\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "\n",
    "        print (\"self.layer_0:\" , self.layer_0.shape )\n",
    "        print (\"Weights 0_1:\", self.weights_0_1.shape )\n",
    "        print (\"Weights 1_2:\", self.weights_1_2.shape )\n",
    "        \n",
    "    #def update_input_layer(self,review):\n",
    "        # TODO: You can copy most of the code you wrote for update_input_layer \n",
    "        #       earlier in this notebook. \n",
    "        #\n",
    "        #       However, MAKE SURE YOU CHANGE ALL VARIABLES TO REFERENCE\n",
    "        #       THE VERSIONS STORED IN THIS OBJECT, NOT THE GLOBAL OBJECTS.\n",
    "        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\n",
    "        #global layer_0\n",
    "        # clear out previous state by resetting the layer to be all 0s\n",
    "     #   self.layer_0 *= 0\n",
    "     #   for word in review.split(\" \"):\n",
    "     #       if(word in self.word2index.keys()):\n",
    "     #           self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        # TODO: Copy the code you wrote for get_target_for_label \n",
    "        #       earlier in this notebook. \n",
    "        if label == 'POSITIVE':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        # TODO: Return the result of calculating the sigmoid activation function\n",
    "        #       shown in the lectures\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        # TODO: Return the derivative of the sigmoid activation function, \n",
    "        #       where \"output\" is the original output from the sigmoid fucntion \n",
    "        return output*(1-output)\n",
    "\n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "        \n",
    "        training_reviews = list()\n",
    "        \n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.lower().split(\" \"):\n",
    "                #print (\"Word:\", word)\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))        \n",
    "            \n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "\n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        print ( 'length =' , len(training_reviews))\n",
    "        #layer_1 = np.zeros((1,self.hidden_nodes))\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            # TODO: Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            # TODO: Implement the forward pass through the network. \n",
    "            #       That means use the given review to update the input layer, \n",
    "            #       then calculate values for the hidden layer,\n",
    "            #       and finally calculate the output layer.\n",
    "            # \n",
    "            #       Do not use an activation function for the hidden layer,\n",
    "            #       but use the sigmoid activation function for the output layer.\n",
    "            \n",
    "            #self.update_input_layer(review)\n",
    "            \n",
    "            # hidden layer output\n",
    "            #layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            \n",
    "            \n",
    "            self.layer_1 *=0\n",
    "           \n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "            \n",
    "            \n",
    "            # Output\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            \n",
    "            # TODO: Implement the back propagation pass here. \n",
    "            #       That means calculate the error for the forward pass's prediction\n",
    "            #       and update the weights in the network according to their\n",
    "            #       contributions toward the error, as calculated via the\n",
    "            #       gradient descent and back propagation algorithms you \n",
    "            #       learned in class.\n",
    "            \n",
    "            #output eror\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            #output error term\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "            \n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
    "            layer_1_delta = layer_1_error\n",
    "            \n",
    "            #Updating weights\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate\n",
    "            #self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta)*self.learning_rate\n",
    "            \n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0]*self.learning_rate\n",
    "            \n",
    "          \n",
    "            # TODO: Keep track of correct predictions. To determine if the prediction was\n",
    "            #       correct, check that the absolute value of the output error \n",
    "            #       is less than 0.5. If so, add one to the correct_so_far count.\n",
    "            #if (layer_2 >= .5 and label == 'POSITIVE'):\n",
    "            #    correct_so_far += 1\n",
    "            #elif(layer_2 < .5 and label == 'NEGATIVE'):\n",
    "            #    correct_so_far += 1\n",
    "            \n",
    "            if (np.abs(layer_2_error) < .5):\n",
    "                correct_so_far += 1\n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"Reviews Done#\" , i)\n",
    "        print (\"layer1\", self.layer_1)\n",
    "        print (\"Layer_1 shape:\", self.layer_1.shape )\n",
    "        print (\"Layer_2 shape:\", layer_2.shape )\n",
    "        print (\"self.weights_0_1:\", self.weights_0_1 )\n",
    "        \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            #print (\"Pred:\", pred, \"Label:\",testing_labels[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "        sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        #Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "    \n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        ## New for Project 5: Removed call to update_input_layer function\n",
    "        #                     because layer_0 is no longer used\n",
    "\n",
    "        # Hidden layer\n",
    "        ## New for Project 5: Identify the indices used in the review and then add\n",
    "        #                     just those weights to layer_1 \n",
    "        \n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "         #   print (\"Word:\", word)\n",
    "            #print ( \"self.word2index.keys():\", self.word2index.keys())\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        #print (\"ui\", len(unique_indices))\n",
    "        #print (\"wi\", len(self.word2index))\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "       \n",
    "        # Output layer\n",
    "        ## New for Project 5: changed to use self.layer_1 instead of local layer_1\n",
    "        #print(\"Layer1:\", self.layer_1)\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "         \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        #print(\"Layer2:\", layer_2)\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.layer_0: (1, 7571)\n",
      "Weights 0_1: (7571, 10)\n",
      "Weights 1_2: (10, 1)\n",
      "length = 24000\n",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%Reviews Done# 0\n",
      "Progress:10.4% Speed(reviews/sec):2006. #Correct:1954 #Trained:2501 Training Accuracy:78.1%Reviews Done# 2500\n",
      "Progress:20.8% Speed(reviews/sec):1929. #Correct:3996 #Trained:5001 Training Accuracy:79.9%Reviews Done# 5000\n",
      "Progress:31.2% Speed(reviews/sec):1910. #Correct:6099 #Trained:7501 Training Accuracy:81.3%Reviews Done# 7500\n",
      "Progress:41.6% Speed(reviews/sec):1923. #Correct:8253 #Trained:10001 Training Accuracy:82.5%Reviews Done# 10000\n",
      "Progress:52.0% Speed(reviews/sec):1917. #Correct:10401 #Trained:12501 Training Accuracy:83.2%Reviews Done# 12500\n",
      "Progress:62.5% Speed(reviews/sec):1916. #Correct:12538 #Trained:15001 Training Accuracy:83.5%Reviews Done# 15000\n",
      "Progress:72.9% Speed(reviews/sec):1918. #Correct:14633 #Trained:17501 Training Accuracy:83.6%Reviews Done# 17500\n",
      "Progress:83.3% Speed(reviews/sec):1913. #Correct:16798 #Trained:20001 Training Accuracy:83.9%Reviews Done# 20000\n",
      "Progress:93.7% Speed(reviews/sec):1912. #Correct:18972 #Trained:22501 Training Accuracy:84.3%Reviews Done# 22500\n",
      "Progress:99.9% Speed(reviews/sec):1910. #Correct:20285 #Trained:24000 Training Accuracy:84.5%layer1 [[-0.52490057  0.19768659  0.17067654  0.34672543 -0.27965294  0.74373283\n",
      "  -0.5638288   0.2459809  -0.10309618  0.08058302]]\n",
      "Layer_1 shape: (1, 10)\n",
      "Layer_2 shape: (1, 1)\n",
      "self.weights_0_1: [[ 0.0035007  -0.00131842 -0.00113829 ..., -0.00164051  0.00068758\n",
      "  -0.00053743]\n",
      " [ 0.01709116 -0.00643682 -0.00555736 ..., -0.00800932  0.00335689\n",
      "  -0.00262384]\n",
      " [-0.02059697  0.00775717  0.00669731 ...,  0.00965223 -0.00404547\n",
      "   0.00316206]\n",
      " ..., \n",
      " [-0.00542949  0.00204484  0.00176545 ...,  0.00254439 -0.00106641\n",
      "   0.00083354]\n",
      " [ 0.00424804 -0.00159988 -0.00138129 ..., -0.00199073  0.00083436\n",
      "  -0.00065216]\n",
      " [ 0.00868661 -0.00327153 -0.00282454 ..., -0.00407075  0.00170614\n",
      "  -0.00133357]]\n"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],min_count=20,polarity_cutoff=0.05,learning_rate=0.01)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-1d80a48c32ef>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1d80a48c32ef>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mlp.test(reviews[-1000:],labels[-1000:])v\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
